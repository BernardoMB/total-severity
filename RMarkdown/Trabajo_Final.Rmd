---
title: "Trabajo final de Cálculo Actuarial III"
author: "Bernardo Mondragón Brozon, Anhara Gámez Rueda"
date: "May 12, 2018"
output: pdf_document
---

<!-- Configure R Markdown file -->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
# Create beautiful graphs
#install.packages("ggplot")
library(ggplot2)
# TeX expressions in graphs labels
#install.packages("latex2exp")
library(latex2exp)
# Calculate Kurtosis skew and other functions
#install.packages("moments")
library(moments)
# Para knitear
#install.packages("knitr")
library(knitr)
# Para imprimir tablas
#install.packages("kableExtra")
library(kableExtra)

# Color?
colorImp <- TRUE
# Colores chidos
moradito <- "#be58a0"
azulito <- "#00e6e6"
```

\section{1.1 La severidad total}

La severidad total esta dada por lo siguiente:
$$ S=x_1+x_2+\cdots+x_N  $$
```{r, parameters, include=FALSE}
set.seed(7031996)
lambda_po <- 0.1
denom <- 10000 # Por la parametrizacion de la exponencial
lambda_exp <- 1/denom
```
En donde $\{x_i\}_{i=1\dots N}$ son variables aleatorias independientes e identicamente distribuidas que indican los montos tal que $x_i$ sigue una distribución exponencial con media $1/\lambda_{exp}=`r denom`$ para toda $i$, y $N$ es la variable aleatoria independiente de las $x_i$'s que indica la frecuencia de los montos tal que sigue una distribución Poisson con media $\lambda_{Po}=`r lambda_po`$ eventos en un año.

Por el teorema de probabilidad total, se tiene que 
$$Pr\{S\leq s|N=n\}=\frac{Pr\{S\leq s,N=n\}}{Pr\{N=n\}}  $$
$$\Rightarrow \quad Pr\{S\leq s,N=n\}=Pr\{N=n\}Pr\{S\leq s|N=n\}.$$
Por lo tanto se tiene que 
$$\begin{aligned}
  F_S(s) &= \sum_{n=0}^{\infty}Pr\{S\leq s,N=n\}  \\
            &= \sum_{n=0}^{\infty}Pr\{N=n\}Pr\{S\leq s|N=n\} \\
            &= \sum_{n=0}^{\infty}Pr\{N=n\}Pr\{\sum_{i=n}^{N}x_i\leq s|N=n\} \\
            &= \sum_{n=0}^{\infty}Pr\{N=n\}F_X^{*n}(s).
\end{aligned}$$

En donde $F_X^{*n}(s)$ es la convolución de las variables aleatorias $\{x_i\}_{i=1\dots N}$, o bien, la funcion de distribucion de probabilidad acumulada de $\sum_{i=n}^{N}x_i$ con $x_i \sim exp(\lambda_{exp}=1/`r  denom`)$. 
Sean $M_{\sum_{i=n}^{N}x_i}(t)$ y $M_{x_1}(t)$ las funciones generadoras de momentos de las variables aleatorias $\sum_{i=n}^{N}x_i$ y $x_1$ respectivamente, entonces, sin pÃ©rdida de generalidad, se tiene que

$$M_{\sum_{i=n}^{N}x_i}(t)=\prod_{i=1}^n M_{x_1}(t)=\prod_{i=1}^n\frac{\lambda_{exp}}{\lambda_{exp}+t}=\left(\frac{\lambda_{exp}}{\lambda_{exp}+t}\right)^n=\left(1-\frac{t}{\lambda_{exp}}\right)^{-n}.$$

Lo cual corresponde a la funcion generadora de momentos de una variable aleatoria distribuida Gamma con parametros de $\alpha = n$ y $\beta = \lambda_{exp}$. Ademas, la distribucion de la frecuencia es Poisson con parametros $\lambda_{Po}=`r lambda_po`$, entonces se sigue que
$$F_S(s)=\sum_{n=0}^{\infty}\frac{\lambda_{Po}^n e^{-\lambda_{Po}}}{n!}\int_0^s \frac{\lambda_{exp}^n}{\Gamma (n)}t^{n-1}e^{-\lambda_{exp}t} \, \mathrm{d}t $$
```{r plot S CDF, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
# CDF Compound Poisson Distribution 
cdf.comp.pois <- function(x, lambda_po=4,lambda_exp=2) {
  # Dont take into account terms of the sum that are smaller than the following tolerance 
  tolerance <- 0.000001
  
  # Define the region of integration
  B <- c(0, x)
  
  # Calculate the sum
  # prob starts in zero because the severity is a positive random variable
  # First term
  prob <- 0 
  if (B[1] == 0) prob <- exp(-lambda_po)
  # The rest of terms
  n <- 1
  repeat {
    next_term <- exp(-lambda_po+n*log(lambda_po)-lfactorial(n)) * pgamma(B[2], shape=n, rate=lambda_exp)
    if (next_term < tolerance) {
      break
    }
    prob <- prob + next_term
    n <- n + 1
  }
  prob
}

# Get values to be ploted
getValues.cdf.comp.pois <- function(x, lambda_po=4, lambda_exp=2) sapply(x, FUN=cdf.comp.pois, lambda_po=lambda_po,lambda_exp=lambda_exp)

# Create a plot
p <- ggplot()

# Plot axes to make it look nicer
xAxis <- geom_hline(yintercept = 0, size = .5)
yAxis <-geom_vline(xintercept = 0, size = .5)

# Plot axes labels
cdf.comp.pois.labels <- labs(x = TeX('$s$'), y = TeX('$F_S(s)$'))
# Title
cdf.comp.pois.title <- ggtitle("Función de probabilidad acumulada \n de la severidad total")
# Center title
title.theme <- theme(plot.title = element_text(hjust = 0.5))

# Insert a horizontal line on y=1 because we are ploting a CDF
asinth.axis <- geom_hline(yintercept=1, size=.1)

# Color
if (colorImp) cdf.comp.pois.color=moradito else cdf.comp.pois.color="black"

# Create layer
cdf.comp.pois.layer <- stat_function(
  aes(x=c(0,10)),
  fun=getValues.cdf.comp.pois,
  args=list(lambda_po=lambda_po, lambda_exp=lambda_exp),
  color=cdf.comp.pois.color
)

# Adjust scales on axes
cdf.xlim <- xlim(0,80000)
cdf.ylim <- ylim(0.88,1)

# Plot the standard CDF
p + xAxis + yAxis + cdf.comp.pois.labels + cdf.comp.pois.title + title.theme + asinth.axis + cdf.comp.pois.layer + cdf.xlim + cdf.ylim
```

La funcion de densidad de probabilidad de la severidad total esta dada por
$$\begin{aligned}
  f_S(s) &= \frac{d}{ds}F_S(s)  \\
            &= \frac{d}{ds}\sum_{n=0}^{\infty}\frac{\lambda_{Po}^n e^{-\lambda_{Po}}}{n!}\int_0^s \frac{\lambda_{exp}^n}{\Gamma (n)}t^{n-1}e^{-\lambda_{exp}t} \, \mathrm{d}t \\
            &= \sum_{n=0}^{\infty}\frac{\lambda_{Po}^n e^{-\lambda_{Po}}}{n!}\frac{d}{ds}\int_0^s \frac{\lambda_{exp}^n}{\Gamma (n)}t^{n-1}e^{-\lambda_{exp}t} \, \mathrm{d}t \\
            &= \sum_{n=0}^{\infty}\frac{\lambda_{Po}^n e^{-\lambda_{Po}}}{n!} \frac{\lambda_{exp}^n}{\Gamma (n)}s^{n-1}e^{-\lambda_{exp}s}
\end{aligned}$$

```{r plot S PDF, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
# PDF Compound Poisson Distribution 
pdf.comp.pois <- function(x, lambda_po=4,lambda_exp=2) {
  # Dont take into account terms of the sum that are smaller than the following tolerance 
  tolerance <- 0.0000000001
  prob <- 0
  # The rest of terms
  n <- 1
  repeat {
    next_term <- exp(-lambda_po+n*log(lambda_po)-lfactorial(n)) * dgamma(x, shape=n, rate=lambda_exp)
    if (next_term < tolerance) {
      break
    }
    prob <- prob + next_term
    n <- n + 1
  }
  prob
}

# Get values to be ploted
getValues.pdf.comp.pois <- function(x, lambda_po=4, lambda_exp=2) sapply(x, FUN=pdf.comp.pois, lambda_po=lambda_po,lambda_exp=lambda_exp)

# Plot axes labels
pdf.comp.pois.labels <- labs(x = TeX('$s$'), y = TeX('$f_S(s)$'))

# Title
pdf.comp.pois.title <- ggtitle("Función de densidad de probabilidad \n de la severidad total")

# Color
if (colorImp) pdf.comp.pois.color <- azulito else pdf.comp.pois.color <- "black"

# Create layer
pdf.comp.pois.layer <- stat_function(
  aes(x=c(0,10)),
  fun=getValues.pdf.comp.pois,
  args=list(lambda_po=lambda_po, lambda_exp=lambda_exp),
  color=pdf.comp.pois.color
)

# Adjust scales on axes
pdf.xlim <- xlim(0,80000)
pdf.ylim <- ylim(0,.00001)

# Plot the standard PDF
p + xAxis + yAxis + pdf.comp.pois.labels + pdf.comp.pois.title + title.theme + pdf.comp.pois.layer + pdf.xlim + pdf.ylim
```

A continuación se presenta una tabla que indica la probabilidad que se acumula en ciertos puntos de la distribución de la severidad total:
```{r percentile table, echo=FALSE, warning=FALSE}
# Percentiles vector
percentiles <- c(0,1,50,100,1000,10000,20000,40000,50000)
probs <- sapply(percentiles, FUN=cdf.comp.pois, lambda_po=lambda_po, lambda_exp=lambda_exp)
percentiles.df <- data.frame(percentiles, probs)
names(percentiles.df) <- c("s","F(s)")
kable(percentiles.df)
```

Como se puede observar, casi toda la probabilidad se acumula en valores muy pequeños para la severidad total.

\section{1.2 Simulación}

Para hacer simulaciones de la severidad total, primero hay que simular el número $N$ de siniestros ocurridos, el cual proviene de la distribución de Poisson con media $\lambda_{Po}=`r lambda_po`$. Una vez simulado el número $N$ de siniestros, se simulan $N$ siniestros, que son variables aleatorias exponenciales con parámetros $\lambda_{exp}=1/`r denom`$. Después de obtener los $N$ siniestros, se suman y de esta manera se obtiene un primer valor de la severidad total. Para concluir con la simulación, se repite el proceso anterior $10000$ veces. A continuación se muestran los primeros $100$ valores obtenidos de la simulacion:

```{r simulated values, echo=FALSE, warning=FALSE, message=FALSE}
severities <- c()
n <- 10000
for(i in 1:n) {
  N <- rpois(1,lambda=lambda_po)
  if (N != 0) {
    exps <- rexp(N, rate=lambda_exp)
    severities <- c(severities, sum(exps))
  } else {
    severities <- c(severities, 0)
  }
}
# Imprimiendo solo 100
kable(matrix(severities[1:100],9))

```

El histograma debe parecerse a la función de densidad de probabilidad (la linea punteada indica la seveidad promedio):

```{r histogram, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
if (colorImp) {
  hist.color <- moradito
  hist.fill <- moradito
  hist.alpha <- "0.2"
} else {
  hist.color <- "black"
  hist.fill <- "white"
  hist.alpha <- "1"
}

severities.df <- data.frame(severities)
breaks <- seq(1, 80000, by=1000)
hist.p <- ggplot(data=severities.df, aes(x=severities)) +
  geom_histogram(breaks=breaks, color=hist.color, fill=hist.fill, alpha=hist.alpha) + 
  labs(x = TeX('Severidad total$'), y = TeX('Frecuencia')) +
  ggtitle("Histograma") + title.theme
hist.p
```

En la siguiente gráfica se puede apreciar que, en efecto, el histograma se parece a la función de densidad de probabilidad (nótese el cambio de escala en el eje y):

```{r histogram with density, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
# Plot the PDF with scaled histogram
# Create a plot
hist.den.p <- ggplot()
hist.p2 <- hist.den.p + xAxis + yAxis + pdf.comp.pois.labels + pdf.comp.pois.title + title.theme + pdf.xlim + pdf.ylim + geom_histogram(data=severities.df, aes(x=severities, y=.0000001*..count..), breaks=breaks, color=hist.color, fill=hist.fill, alpha=hist.alpha) + pdf.comp.pois.layer
hist.p2
# For more info about ploting density and histogram
# https://stat.ethz.ch/pipermail/r-help/2011-June/280588.html
```

\section{1.3 Comparación de los valores reales con los estimados}

Se vio que la severidad total, que sigue uns distribucion de Poisson Compuesta, está dada por
$$  S=\sum_{i=1}^{N}x_i.$$
Entonces el valor esperado de la severidad total está dado por
$$\begin{aligned}
  E(S) &= E\left(\sum_{i=1}^{N}x_i\right)=E(E(S|N=n))=E\left(\sum_{i=1}^{n}x_i\bigg\rvert N=n\right)=E(NE(x_1))  \\
            &= E\left(N\left(\frac{1}{\lambda_{exp}}\right)\right)=\frac{1}{\lambda_{exp}E(N)}=\frac{\lambda_{exp}}{\lambda_{Po}}=\frac{10000}{0.1}=1000
\end{aligned}$$
y su varianza está dada por
$$\begin{aligned}
  Var(S) &= Var(E(S|N)) + E(Var(S|N)) = Var(NE(x_1))+E(NVar(x_1)) \\
            &=\frac{1}{\lambda_{exp}}Var(N) + \frac{1}{\lambda_{exp}^2}E(N) = \frac{\lambda_{Po}}{\lambda_{exp}} + \frac{\lambda_{Po}}{\lambda_{exp}^2}=(10000)(0.1) + (10000)^2(0.1)=10001000
\end{aligned},$$
de manera que su desviacion estandar es la siguinete:  
$$\sqrt{Var(S)}=\sqrt{10001000}=3162.43577.$$
La función generadora de momentos de $S$ está dada por
$$M_{S}(t)=E\left(e^{N\ln\left(e^{x_{1}t}\right)}\right)=M_{N}(\ln\left(x_{1}t\right))=e^{\lambda_{Po}\left(\frac{\lambda_{exp}}{\lambda_{exp}+t}-1\right)} $$

se sigue que el sesgo de la distribucion es positivo y está dado por
$$E\left((S-E(S))^3\right)=\lambda_{Po}E(x_1^3)=\lambda_{Po}M^{(3)}_{x_1}(0)=\lambda_{Po}\frac{6}{\lambda_{exp}^3}=(0.1)(6)(10000)^3=6\times 10^{11},$$
y el coeficiente de Kurtosis es
$$ \frac{E(S^4)}{Var(S)^2}=\frac{M_{s}^{(4)}(0)}{\left(\frac{\lambda_{Po}}{\lambda_{exp}} + \frac{\lambda_{Po}}{\lambda_{exp}^2}\right)^2}=\frac{\frac{\lambda_{Po}^4+12\lambda_{Po}^3+36\lambda_{Po}^2+24\lambda_{Po}}{\lambda_{exp}^4}}{10001000^2}=\frac{\frac{(0.1)^4+12(0.1)^3+36(0.1)^2+24(0.1)}{(1/10000)^4}}{10001000^2}=277.1545. $$

Con valores simulados, se tienen las siguientes estimaciones para la severidad total

```{r comparando con valores estimados, echo=FALSE}
#value <- c("Media","Varianza","Sesgo","Kurtosis")
#formula <- c("$\\bar{s}=\\frac{1}{n}\\sum_{i=0}^{n}s_i$","$\\frac{1}{n-1}\\sum_{i=0}^{n}\\left(s_i-\\bar{s}\\right)$","${\\frac{{\\tfrac {1}{n}}\\sum _{i=1}^{n}(x_{i}-{\\overline{x}})^{3}}{\\left({\\tfrac {1}{n-1}}\\sum _{i=1}^{n}(x_{i}-{\\overline{x}})^{2}\\right)^{3/2}}}$","${\\frac{{\\tfrac{1}{n}}\\sum _{i=1}^{n}(s_{i}-{\\overline {s}})^{4}}{\\left({\\tfrac{1}{n}}\\sum _{i=1}^{n}(s_{i}-{\\overline {s}})^{2}\\right)^{2}}}-3$")
#real <- c(1000,10001000,"$6\\times10^{11}$",277.1545)
#estimate <- c(mean(severities),var(severities),skew(severities),kurtosis(severities))
#df.values <- data.frame(value, formula, estimate, real)
#names(df.values) <- c("Valor","Formula","Estimado","Real")
#kable(df.values)
```

\section{1.4 Aproximación de la distribución de la severidad total}

La función de distribución Poisson Compuesta puede ser aproximada mediante una distribución Gamma trasladada con los siguientes parámetros: 
$$\alpha=\frac{4\lambda_{Po}E\left(x_1^{2}\right)^3}{E\left(x_1^3\right)^2}=\frac{4\lambda_{Po}\left(\frac{2}{\lambda_{exp}^2}\right)^3}{\left(\frac{6}{\lambda_{exp}^3}\right)^2}=\frac{4}{45}, \quad \beta=\frac{2E\left(x_1^2\right)}{E\left(x_1^3\right)}=\frac{2\left(\frac{2}{\lambda_{exp}^2}\right)}{\left(\frac{6}{\lambda_{exp}^3}\right)}=\frac{1}{15000}$$

y un desplazamiento
$$x_0=\lambda_{Po}E\left(x_1\right)-\frac{2\lambda_{Po}E(x_1^2)^2}{E(x_1^3)}=\lambda_{Po}\left(\frac{1}{\lambda_{exp}}\right)-\frac{2\lambda_{Po}\left(\frac{2}{\lambda_{exp}^2}\right)^2}{\left(\frac{6}{\lambda_{exp}^3}\right)}=-\frac{1000}{3}$$
Observe que la aproximación es buena para valores distantes de la media de la distribución Poisson Compuesta: 
```{r densidad vs aproximacion gamma, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
# PDF Gamma Trasladada
getValues.pdf.gamma.tras <- function(x, desp=1, alpha=4, beta=2) {
  dgamma(x-desp, shape = alpha, rate=beta)
}

# Stablish theme
comp.theme <- theme(
  #panel.grid.major = element_blank(), 
  #panel.grid.minor = element_blank(),
  #panel.background = element_blank(),
  
  # Legend position
  legend.position = c(1, 1),
  legend.justification = c("right", "top"),
  legend.box.just = "right",
  
  # Legend boxes
  legend.key = element_rect(colour = 'black', fill = 'transparent', size = .5, linetype=0),
  legend.key.width = unit(1.5, "lines"),
  legend.background = element_rect(fill="transparent"),
  # Center plot title
  plot.title = element_text(hjust = 0.5),
  legend.text=element_text(size=8)
)

# Title
comp.title <- ggtitle("Densidad de la severidad total \n vs. \n aproximación Gamma")

# Number of different function to be ploted
types <- c("1","2")
# Create plot
comp.p <- ggplot(data.frame(type=types), aes(colour=type, linetype=type, size=type))
# Create layers
pdf.comp.pois.layer.path <- geom_path(
  data=data.frame(type="1"),
  stat="function",
  fun = getValues.pdf.comp.pois,
  args=list(lambda_po=lambda_po, lambda_exp=lambda_exp),
  aes(colour=type, linetype=type, size=type)
)
pdf.gam.layer <- stat_function(
  data=data.frame(type="2"),
  fun = getValues.pdf.gamma.tras,
  args = list(desp=-1000/3, alpha=4/45, beta=1/15000),
  aes(colour=type, linetype=type, size=type)
)
# Colors and line types
if (colorImp) {
  aprox.color <- moradito
  colors <- c(pdf.comp.pois.color,aprox.color)
  sizes <- c(.5,.5)
  linetypes <-c(1,1)
} else {
  colors <- c("black", "black")
  sizes <- c(.5,.5)
  linetypes <-c(1,5)
}
# Legends
comp.an <- labs(TeX('Severidad total'), TeX('aproximacion Gamma'))

# Plot
comp.p + comp.theme + xAxis + yAxis + pdf.comp.pois.labels + comp.title + pdf.xlim + pdf.ylim + pdf.comp.pois.layer.path + pdf.gam.layer +
  scale_colour_manual(
    #name="Densidades", 
    name=NULL, 
    values=colors,
    labels = comp.an,
    breaks = types
  ) + 
  scale_linetype_manual(
    #name="Densidades", 
    name=NULL,
    values = linetypes,
    labels = comp.an,
    breaks = types
  ) +
  scale_size_manual(
    #name="Densidades", 
    name=NULL,
    values = sizes,
    labels = comp.an,
    breaks = types
  )

```
Para valores cercanos a la media es mas conveniente aproximar la distribucion Poisson Compuesta con una distribucion Normal con los siguientes parametros: 
$$\mu=E(N)E(X_1)=\frac{\lambda_{Po}}{\lambda_{exp}}=(0.1)(10000)=1000, $$
$$\sigma^2={E(x_1)}Var(N) + Var(x_1)E(N) = \frac{\lambda_{Po}}{\lambda_{exp}} + \frac{\lambda_{Po}}{\lambda_{exp}^2}=(10000)(0.1) + (10000)^2(0.1)=10001000$$
Sin embargo, esto solo funciona para valores grandes de $\lambda_{Po}$. En el siguinete gráfico se muestra que la aproximación Normal para valores alrededor de la media es bastante mala, pues como $\lambda_{Po}$ es pequeña la media de la suma de variables aleatorias no corverge a la media de la aproximación Normal:

```{r densidad vs aproximacion normal, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
# PDF Compound Poisson Distribution 
dpoiscomp <- function(x, lambda_po=4,lambda_exp=2) {
  # Dont take into account terms of the sum that are smaller than the following tolerance 
  tolerance <- 0.0000000001
  prob <- 0
  # The rest of terms
  n <- 1
  repeat {
    next_term <- exp(-lambda_po+n*log(lambda_po)-lfactorial(n)) * dgamma(x, shape=n, rate=lambda_exp)
    if (next_term < tolerance) {
      break
    }
    prob <- prob + next_term
    n <- n + 1
  }
  prob
}

# Get values to be ploted
getValues.pdf.pois.comp <- function(x, lambda_po=4, lambda_exp=2) sapply(x, FUN=dpoiscomp, lambda_po=lambda_po,lambda_exp=lambda_exp)

# PDF Gamma Trasladada
getValues.pdf.gamma.tras <- function(x, desp=1, alpha=4, beta=2) {
  dgamma(x-desp, shape = alpha, rate=beta)
}

# Create a plot
p <- ggplot()

# Stablish background and leyend position
theme <- theme(
  # Background
  #panel.grid.major = element_blank(), 
  #panel.grid.minor = element_blank(),
  #panel.background = element_blank(),
  
  # Legend position
  legend.position = c(1, 1),
  legend.justification = c("right", "top"),
  legend.box.just = "right",
  
  # Legend boxes
  legend.key = element_rect(colour = 'black', fill = 'transparent', size = .5, linetype=0),
  legend.key.width = unit(1.5, "lines"),
  legend.background = element_rect(fill="transparent"),
  # Center plot title
  plot.title = element_text(hjust = 0.5),
  legend.text=element_text(size=8)
)
# Plot axes to make it look nicer
xAxis <- geom_hline(yintercept = 0, size = .1)
yAxis <-geom_vline(xintercept = 0, size = .1)

# Plot PDFs
# Labels
labels <- labs(x = TeX('$s$'), y = TeX('$f_S(s)$'))
# Title
title <- ggtitle("Densidad de la severidad total \n vs. \n aproximación Normal")
# Empty plot
# Number of different function to be ploted
types <- c("1","2")
# Create plot
p1 <- ggplot(data.frame(type=types), aes(colour=type, linetype=type, size=type))
# Create layers
pdf1 <- geom_path(
  data=data.frame(type="1"),
  stat="function",
  fun = getValues.pdf.pois.comp,
  args=list(lambda_po=0.1, lambda_exp=1/10000),
  aes(colour=type, linetype=type, size=type)
)
pdf2 <- stat_function(
  data=data.frame(type="2"),
  fun = dnorm,
  args = list(mean=1000, sd=sqrt((0.1)*(10000^2))),
  aes(colour=type, linetype=type, size=type)
)
# Colors and line types
if (colorImp) {
  aprox.color <- moradito
  colors <- c(pdf.comp.pois.color,aprox.color)
  sizes <- c(.5,.5)
  linetypes <-c(1,1)
} else {
  colors <- c("black", "black")
  sizes <- c(.5,.5)
  linetypes <-c(1,5)
}
# Legends
an <- labs(TeX('Severidad total'), TeX('aproximación Normal'))

# Plot
p1 + theme + xAxis + yAxis + labels + title + pdf.xlim + pdf.ylim + pdf1 + pdf2 +
  scale_colour_manual(
    #name="Densidades", 
    name=NULL, 
    values=colors,
    labels = an,
    breaks = types
  ) + 
  scale_linetype_manual(
    #name="Densidades", 
    name=NULL,
    values = linetypes,
    labels = an,
    breaks = types
  ) +
  scale_size_manual(
    #name="Densidades", 
    name=NULL,
    values = sizes,
    labels = an,
    breaks = types
  )
```

En este caso, la media de la distribución de la frecuencia de los siniestros en un año es un valor muy pequeño dado por $\lambda_{Po}=`r lambda_po`$, entonces, lo más recomendable para estimar percentiles alrededor de la media, es aproximar la función de distribución mediante una distribución lognormal:

```{r densidad vs aproximacion lognormal, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
get.dlnorm <- function(x, corr=0, meanlog=0, sdlog=1) {
  dlnorm(x-corr, meanlog = meanlog, sdlog = sdlog)
}

# Plot PDFs
# Labels
labels.comp <- labs(x = TeX('$s$'), y = TeX('$f_S(s)$'))
# Title
title.comp <- ggtitle("Densidad de la severidad total \n vs. \n aproximación Lognormal")
# Empty plot
# Number of different function to be ploted
types <- c("1","2")
# Create plot
p1 <- ggplot(data.frame(type=types), aes(colour=type, linetype=type, size=type))
# Create layers
pdf1.pois.comp <- geom_path(
  data=data.frame(type="1"),
  stat="function",
  fun = getValues.pdf.pois.comp,
  args=list(lambda_po=0.1, lambda_exp=1/10000),
  aes(colour=type, linetype=type, size=type)
)
pdf2.log.norm <- stat_function(
  data=data.frame(type="2"),
  fun = get.dlnorm,
  args = list(corr=-5000,meanlog = 4, sdlog = 5),
  aes(colour=type, linetype=type, size=type)
)
# Legends
an <- labs(TeX('Severidad total'), TeX('aproximación Lognormal'))
# Plot
p1 + theme + xAxis + yAxis + labels.comp + title.comp + 
  xlim(0,80000) + 
  ylim(0,.00001) + 
  pdf1.pois.comp + pdf2.log.norm +
  scale_colour_manual(
    #name="Densidades", 
    name=NULL, 
    values=colors,
    labels = an,
    breaks = types
  ) + 
  scale_linetype_manual(
    #name="Densidades", 
    name=NULL,
    values = linetypes,
    labels = an,
    breaks = types
  ) +
  scale_size_manual(
    #name="Densidades", 
    name=NULL,
    values = sizes,
    labels = an,
    breaks = types
  )
```

Esta proximación Lognormal tiene un corrimiento igual $5000$, una media de $4$ y una desviación estándar de $5$.


\section{1.3 Distribución empírica}

La distribución empírica de la severidad total está dada por

```{r, Preg. 2.3 Distribucion empirica de la severidad, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
df <- data.frame(severities)
theme <- theme(
  # Center plot title
  plot.title = element_text(hjust = 0.5)
)
if (colorImp) emp.color <- azulito else emp.color <- "black"
ggplot() + stat_ecdf(data=df, aes(x=severities), geom = "step", color=emp.color) +
  labs(x = TeX('$s$'), y = TeX('$F_{S_n}(s)$')) + asinth.axis + xAxis + yAxis +
  ggtitle("distribución empírica de la severidad total") + theme + cdf.ylim
```

Entonces, un intervalo de confianza a un nivel de $(1-\alpha)100\%$ para distribución de la serveridad total $F_{S}(s)$ está dado por
$$\left(F_{s_n}(s)-\sqrt\frac{\ln\frac{2}{\alpha}}{2n}, F_{s_n}(s)+\sqrt\frac{\ln\frac{2}{\alpha}}{2n}\right)$$
Si se construyen los intervalos de confianza al $95\%$ para $F_S(s)$ utilizando la distribución empírica se tiene lo siguiente:
```{r, echo=FALSE, warning=FALSE}
Fn <- c(1:10000)
ordenados <- sort(severities)
alfa <- 0.05
limsup <- c(1:10000)
liminf <- c(1:10000)
for (i in 1:10000) {
  cuenta<-0
  for (j in 1:10000) {
    if (ordenados[j]<=ordenados[i]){
      cuenta=cuenta+1
    }
  }
  Fn[i] <- cuenta/10000
  limsup[i] <- Fn[i] + sqrt(log(2/alfa)/(2*10000))
  if (limsup[i] > 1) limsup[i] <- 1
  liminf[i] <- Fn[i] - sqrt(log(2/alfa)/(2*10000))
}
```

```{r, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
types <- c("1","2","3","4")
p <- ggplot(data.frame(type=types), aes(colour=type, linetype=type, size=type))
theme <- theme(
  # Leyend position
  legend.position = c(1, 0),
  legend.justification = c("right", "bottom"),
  legend.box.just = "right",
  # Legend boxes
  legend.key = element_rect(colour = 'black', fill = 'transparent', size = .5, linetype=0),
  legend.key.width = unit(1.5, "lines"),
  legend.background = element_rect(fill="transparent"),
  # Center plot title
  plot.title = element_text(hjust = 0.5),
  legend.text=element_text(size=8)
)
xAxis <- geom_hline(yintercept = 0, size = .1)
yAxis <-geom_vline(xintercept = 0, size = .1)
labels <- labs(x = TeX('$s$'), y = TeX('$F_{S_n}(s)$'))
title <- ggtitle("Intervalos de confianza al 95% para \n la distribución de la severidad total")

fun2 <- geom_step(data=data.frame(ordenados,limsup, type="1"), aes(x=ordenados, y=limsup, colour=type, linetype=type, size=type)) 
fun1 <- geom_step(data=data.frame(ordenados,Fn, type="3"), aes(x=ordenados, y=Fn, colour=type, linetype=type, size=type)) 
fun3 <- geom_step(data=data.frame(ordenados,liminf, type="4"), aes(x=ordenados, y=liminf, colour=type, linetype=type, size=type)) 
cdf.layer <- geom_path(
  data=data.frame(type="2"),
  stat="function",
  fun=getValues.cdf.comp.pois,
  args=list(lambda_po=lambda_po, lambda_exp=lambda_exp),
  aes(colour=type, linetype=type, size=type)
)
an <- labs(TeX('Cota superior'), TeX('teórica'),TeX('empírica'), TeX('Cota inferior'))

if (colorImp) {
  colors <- c("#800080", "#ffa500", "#add8e6","purple")
  sizes <- c(.4,2,1,.4)
  linetypes <- c(1,1,1,1)
} else {
  colors <- c("black","black","black","black")
  sizes <- c(1,1,1,1)
  linetypes <-c(1,2,3,4)
}

p+theme+xAxis+yAxis+labels+title+cdf.layer+fun1+fun2+fun3+cdf.xlim+cdf.ylim+ asinth.axis +
scale_colour_manual(
  #name="Name",
  name = NULL,
  values = colors,
  labels = an,
  breaks = types
) +
scale_linetype_manual(
  #name="Name",
  name = NULL,
  values = linetypes,
  labels = an,
  breaks = types
) +
scale_size_manual(
  #name="Name",
  name = NULL,
  values = sizes,
  labels = an,
  breaks = types
)

```


\section{Estimación de la frecuencia y severidad}

\subsection{2.1 Simulación de los pares $\left(T_i,x_i\right)$}

Como la frecuencia de los eventos en un añoo se distribuye Poisson con media $\lambda_{Po}=`r lambda_po`$, entonces las diferencias de tiempo entre las ocurrencias de los eventos siguen una distribución exponencial con media $1/\lambda=\lambda_{Po}=`r lambda_po`$, es decir, los tiempos inter-arribos siguen una distribución exponencial con media $1/\lambda=\lambda_{Po}=`r lambda_po`$. Simulando los tiempos inter-arribos exponenciales, se puden simular las fechas de ocurrencia de los siniestros a partir de hoy. A continuación se muestran las primeras $10$ realizaciones de las fechas de los siniestros y los montos correspondientes distribuidos exponencialmente con media $1/\lambda_{exp}=`r denom`$:

```{r simulated pairs, echo=FALSE, warning=FALSE, message=FALSE}

rate   <- lambda_po
start  <- 2018
# Tiempo interarribos
per <- rexp(10000, rate=rate)
# Obtener las fechas de los cinistros
per[1] <- per[1]+start
# Fechas de los siniestros
PerTot <- cumsum(per)
# Montos de los siniestros
montos <- rexp(10000 ,rate=lambda_exp)

convert.seconds <- function(x) {
  a <- x-2018
  b <- a*31556952
  c <- as.POSIXct(b, origin = "2018-01-01", tz = "UTC")
  as.character(c)
}
dates <- sapply(PerTot, convert.seconds)


pairs.df <- data.frame(dates, montos)
names(pairs.df) <- c("Fechas", "Montos")
kable(head(pairs.df, 10))
```

\pagebreak

\subsection{2.2 Serie de tiempo} 

A continuación se muestra la serie de tiempo generada

```{r, serie de tiempo, echo=FALSE, fig.height = 12, fig.width = 10}
# Ploting time series
# https://www.neonscience.org/dc-time-series-plot-ggplot-r
fechonsias <- pairs.df[[1]]
funciononsia <- function(x) {
  value <- NA
  if (match(x,fechonsias) %% 500 !=0) {
    value <- NA
  } else {
    fechaSeparada <- strsplit(as.character(x), " ")
    value <- fechaSeparada[[1]][1]
  }
  value
}
fechunias <- sapply(fechonsias, funciononsia)
montunios <- pairs.df[[2]]
dfonsio <- data.frame(fechunias, montunios)
names(dfonsio) <- c("fechonson", "montonson")

ggplot(data = dfonsio, aes(x = c(1:10000), y = montonson, group = 1)) + 
  geom_bar(stat="identity", color = "#00AFBB", size = .1, alpha=.1, na.rm = TRUE) +
  geom_point(size=.005, color="blue", alpha=0.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=5)) + 
  scale_x_discrete(limits=dfonsio[[1]], na.translate = FALSE) + xlab("Fecha") + ylab("Monto") + 
  geom_hline(yintercept=10000, size=1, color="cyan") + coord_flip() + scale_y_reverse()
```

La linea azul claro indica la media de la distribución teorica a partir de la cual fueron simulados los datos.

\subsection{2.3 Distribución empírica de la severidad}

Con los valores simulados de los montos, se puede construir la función de distribución de probabilidad empírica de la severidad:

```{r calculo empirica severidad, echo=FALSE, warning=FALSE}
Fn.sev <- c(1:10000)
empirica<-ecdf(montos)
ordenados.sev <- sort(montos)
alfa.sev <- 0.05
limsup.sev <- c(1:10000)
liminf.sev <- c(1:10000)
for (i in 1:10000) {
  cuenta<-0
  for (j in 1:10000) {
    if (ordenados.sev[j]<=ordenados.sev[i]){
      cuenta=cuenta+1
    }
  }
  Fn.sev[i] <- cuenta/10000
  limsup.sev[i] <- Fn.sev[i] + sqrt(log(2/alfa.sev)/(2*10000))
  if (limsup.sev[i] > 1) limsup.sev[i] <- 1
  liminf.sev[i] <- Fn.sev[i] - sqrt(log(2/alfa)/(2*10000))
}
```

```{r, distribucion empirica de la severidad, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
types <- c("1","2","3","4")
p <- ggplot(data.frame(type=types), aes(colour=type, linetype=type, size=type))
theme <- theme(
  # Leyend position
  legend.position = c(1, 0),
  legend.justification = c("right", "bottom"),
  legend.box.just = "right",
  # Legend boxes
  legend.key = element_rect(colour = 'black', fill = 'transparent', size = .5, linetype=0),
  legend.key.width = unit(1.5, "lines"),
  legend.background = element_rect(fill="transparent"),
  # Center plot title
  plot.title = element_text(hjust = 0.5),
  legend.text=element_text(size=8)
)
xAxis <- geom_hline(yintercept = 0, size = .1)
yAxis <-geom_vline(xintercept = 0, size = .1)
labels <- labs(x = TeX('$m$ (montos)'), y = TeX('$F_{M_n}(m)$'))
title <- ggtitle("Intervalos de confianza al 95% para \n la distribución de la severidad")

ordenados.sev <- sort(montos)
fun2 <- geom_step(data=data.frame(ordenados.sev,limsup, type="1"), aes(x=ordenados.sev, y=limsup.sev, colour=type, linetype=type, size=type)) 
fun1 <- geom_step(data=data.frame(ordenados.sev,Fn, type="3"), aes(x=ordenados.sev, y=Fn.sev, colour=type, linetype=type, size=type)) 
fun3 <- geom_step(data=data.frame(ordenados.sev,liminf, type="4"), aes(x=ordenados.sev, y=liminf.sev, colour=type, linetype=type, size=type)) 
cdf.layer <- geom_path(
  data=data.frame(type="2"),
  stat="function",
  fun=pexp,
  args=list(rate=lambda_exp),
  aes(colour=type, linetype=type, size=type)
)
an <- labs(TeX('Cota superior'), TeX('teórica'),TeX('empírica'), TeX('Cota inferior'))

if (colorImp) {
  colors <- c("#800080", "#ffa500", "#add8e6","purple")
  sizes <- c(.4,2,1,.4)
  linetypes <- c(1,1,1,1)
} else {
  colors <- c("black","black","black","black")
  sizes <- c(1,1,1,1)
  linetypes <-c(1,2,3,4)
}

p+theme+xAxis+yAxis+labels+title+cdf.layer+fun1+fun2+fun3+cdf.xlim+ylim(0,1)+ asinth.axis +
scale_colour_manual(
  #name="Name",
  name = NULL,
  values = colors,
  labels = an,
  breaks = types
) +
scale_linetype_manual(
  #name="Name",
  name = NULL,
  values = linetypes,
  labels = an,
  breaks = types
) +
scale_size_manual(
  #name="Name",
  name = NULL,
  values = sizes,
  labels = an,
  breaks = types
)
```

Dado el numero de observaciones (simulaciones) $n=10000$, se tiene que la función de distribución empírica de la severidad se aproxima bastante bien a la función de distribución teórica y la longitud de los intervalos de confianza no es muy grande. Note que las cotas superiores e inferiores "abrazan estrechamente" a la función de distribución teórica. 

\subsection{2.4 Histograma de la severidad}

Agrupando los montos de los siniestros en intervalos de longitud $5000$, se obtiene el siguinete histograma:
```{r histograma severidad, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
if (colorImp) {
  hist.color <- moradito
  hist.fill <- moradito
  hist.alpha <- "0.2"
} else {
  hist.color <- "black"
  hist.fill <- "white"
  hist.alpha <- "1"
}

montos.df <- data.frame(montos)
breaks <- seq(1, 80000, by=5000)
hist.p <- ggplot(data=montos.df, aes(x=montos)) +
  geom_histogram(breaks=breaks, color=hist.color, fill=hist.fill, alpha=hist.alpha) + 
  labs(x = TeX('Severidad$'), y = TeX('Frecuencia')) +
  ggtitle("Histograma de la severidad") + title.theme
hist.p
```

Con un escalamiento adecuado sobre las frecuencias (note el cambio en la escala en el eje $y$), se puede observar la enorme similitud entre la densidad y el histograma:

```{r  histograma con densidad sev, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}

pdf.sev.layer <- stat_function(
  aes(x=c(0,10)),
  fun=dexp,
  args=list(rate=lambda_exp),
  color=azulito
)

hist.p2.sev <- ggplot() + xAxis + yAxis + title.theme + pdf.xlim + ylim(0,.0001) + geom_histogram(data=montos.df, aes(x=montos, y=.00000002*..count..), breaks=breaks, color=hist.color, fill=hist.fill, alpha=hist.alpha) + pdf.sev.layer +
  ggtitle("función de densidad de probabilidad \n de la severidad total") +
  labs(x = TeX('$s$'), y = TeX('$f_S(s)$'))
hist.p2.sev
```

\subsection{2.5 Características de la distribución empírica}

Sea $M$ la variable aleatoria que indica el monto de un siniestro, entonces el valor esperado de $M$ limitado a $l$ está dada por

$$  E\left( \min{M, l} \right)=\int_{0}^{l}S_{x_1}(t) \, \mathrm{d}t=\int_{0}^{l} e^{-\lambda_{exp}t} \, \mathrm{d}t = \frac{1-e^{-\lambda_{exp}l}}{\lambda_{exp}} $$

A continuacion se presenta a la \textbf{media limitada} de los montos como funcion del limite:

```{r media limitada, echo=FALSE, warning=FALSE, message=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
sortedSeverities <- sort(unique(montos))
 
# Medias limitadas usando datos empiricos
n=10000
mediasLimitadas <- NULL
for (i in 1:length(sortedSeverities)) {
  u <- sortedSeverities[i]
  mediasLimitadas[i] <- (sum(montos>u)*u + sum(montos[montos<=u]))/n
}

# Media limitada analiticamente como funcion del limite
limitedMean <- function(x) (1-exp(-lambda_exp*x))/(lambda_exp)

types <- c("1","2")
p.m <- ggplot(data.frame(type=types), aes(colour=type, linetype=type, size=type))
theme <- theme(
   # Leyend position
   legend.position = c(1, 0),
   legend.justification = c("right", "bottom"),
   legend.box.just = "right",
   # Legend boxes
   legend.key = element_rect(colour = 'black', fill = 'transparent', size = .5, linetype=0),
   legend.key.width = unit(1.5, "lines"),
   legend.background = element_rect(fill="transparent"),
   # Center plot title
   plot.title = element_text(hjust = 0.5),
   legend.text=element_text(size=8)
 )
 xAxis <- geom_hline(yintercept = 0, size = .1)
 yAxis <-geom_vline(xintercept = 0, size = .1)
 labels <- labs(x = TeX('$s$'), y = TeX('$F_{S_n}(s)$'))
 title <- ggtitle("Funcion media limiatada")
 
 points <- geom_point(
   data=data.frame(sortedSeverities, mediasLimitadas, type="1"),
   aes(x=sortedSeverities, y=mediasLimitadas, colour=type, linetype=type, size=type),
   shape=0
 )
 
 curve <- geom_path(
   data=data.frame(type="2"),
   stat="function",
   fun=limitedMean,
   aes(colour=type, linetype=type, size=type)
 )
 
 an <- labs(TeX('Valores simulados'), TeX('Media limitada'))
 
 if (colorImp) {
   colors <- c(moradito,azulito)
   sizes <- c(.3,1)
   linetypes <- c(1,1)
 } else {
   colors <- c("black","black")
   sizes <- c(1,1)
   linetypes <-c(1,2)
 }
 
 p.m+theme+xAxis+yAxis+labs(x="Limite", y="Media limitada")+title+curve+points+xlim(0,80000)+ylim(0,10000)+ asinth.axis +
 scale_colour_manual(
   #name="Name",
   name = NULL,
   values = colors,
   labels = an,
   breaks = types
 ) +
 scale_linetype_manual(
   #name="Name",
   name = NULL,
   values = linetypes,
   labels = an,
   breaks = types
 ) +
 scale_size_manual(
   #name="Name",
   name = NULL,
   values = sizes,
   labels = an,
   breaks = types
 )
```

Como los montos son distribuidos exponencialmente con media $E(x_1)=1/\lambda_{exp}$, no se observan indicios de una distribucion de cola pesada.
 
 La \textbf{media en exceso} como funcion del umbral es la siguiente:

```{r media en exceso, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
 # Medias en exceso usando datos empiricos
 mediasEnExceso <- NULL
 for(i in 1:length(sortedSeverities)){
   d <- sortedSeverities[i]
   mediasEnExceso[i] <- sum(montos[montos>d]-d)/sum(montos>d)
 }
 
# Media limitada analiticamente como funcion del limite
 excesMean <- function(x, param=1) param
 
 types <- c("1","2")
 p.m <- ggplot(data.frame(type=types), aes(colour=type, linetype=type, size=type))
 theme <- theme(
   # Leyend position
   legend.position = c(1, 0),
   legend.justification = c("right", "bottom"),
   legend.box.just = "right",
   # Legend boxes
   legend.key = element_rect(colour = 'black', fill = 'transparent', size = .5, linetype=0),
   legend.key.width = unit(1.5, "lines"),
   legend.background = element_rect(fill="transparent"),
   # Center plot title
   plot.title = element_text(hjust = 0.5),
   legend.text=element_text(size=8)
 )
 xAxis <- geom_hline(yintercept = 0, size = .1)
 yAxis <-geom_vline(xintercept = 0, size = .1)
 labels <- labs(x = TeX('$s$'), y = TeX('$F_{S_n}(s)$'))
 title <- ggtitle("Funcion media en exceso")
 
 points <- geom_point(
   data=data.frame(sortedSeverities, mediasEnExceso, type="1"),
   aes(x=sortedSeverities, y=mediasEnExceso, colour=type, linetype=type, size=type),
   shape=1
 )
 
 curve <- geom_path(
   data=data.frame(type="2"),
   stat="function",
   fun=excesMean,
   args=list(param=10000),
   aes(colour=type, linetype=type, size=type)
 )
 
 an <- labs(TeX('Valores simulados'), TeX('Media en exceso'))
 
 p.m+theme+xAxis+yAxis+labs(x="Umbral", y="Media en exceso")+title+curve+points+xlim(0,80000)+ylim(0,15000)+ asinth.axis +
 scale_colour_manual(
   #name="Name",
   name = NULL,
   values = colors,
   labels = an,
   breaks = types
 ) +
 scale_linetype_manual(
   #name="Name",
   name = NULL,
   values = linetypes,
   labels = an,
   breaks = types
 ) +
 scale_size_manual(
   #name="Name",
   name = NULL,
   values = sizes,
   labels = an,
   breaks = types
 )
```

Claramente los montos de los siniestros no son un fenomeno de colas pesadas, pues se observa que la media en exceso descrece.
 
La \text{mortalidad empirica} como funcion del monto es la siguiente:

```{r mortalidad empirica, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
 # Mortalidad utilizando datos empirica
 fn <- NULL
 mortalidades <- NULL
 for (i in 1:length(sortedSeverities)) {
   fn[i] <- empirica(sortedSeverities[i+1])-empirica(sortedSeverities[i])
   mortalidades[i] <- fn[i]/(1-empirica(sortedSeverities[i]))
 }
 
 # Funcion de mortalidad
 hazardRate <- function(x, param=1) 1/param
 
 types <- c("1","2")
 p.m <- ggplot(data.frame(type=types), aes(colour=type, linetype=type, size=type))
 theme <- theme(
   # Leyend position
   legend.position = c(0.05, 1),
   legend.justification = c("left", "top"),
   legend.box.just = "right",
   # Legend boxes
   legend.key = element_rect(colour = 'black', fill = 'transparent', size = .5, linetype=0),
   legend.key.width = unit(1.5, "lines"),
   legend.background = element_rect(fill="transparent"),
   # Center plot title
   plot.title = element_text(hjust = 0.5),
   legend.text=element_text(size=8)
 )
 xAxis <- geom_hline(yintercept = 0, size = .1)
 yAxis <-geom_vline(xintercept = 0, size = .1)
 labels <- labs(x = TeX('$s$'), y = TeX('$F_{S_n}(s)$'))
 title <- ggtitle("Funcion mortalidad")
 
 points <- geom_point(
   data=data.frame(sortedSeverities, mortalidades, type="1"),
   aes(x=sortedSeverities, y=mortalidades, colour=type, linetype=type, size=type),
   shape=1
 )
 
 curve <- geom_path(
   data=data.frame(type="2"),
   stat="function",
   fun=hazardRate,
   args=list(param=10000),
   aes(colour=type, linetype=type, size=type)
 )
 
 an <- labs(TeX('Valores simulados'), TeX('Mortalidad = 1/10000'))
 
 p.m+theme+xAxis+yAxis+labs(x="Montos", y="Mortalidad")+title+curve+points+xlim(0,85000)+ylim(0,1)+ asinth.axis +
 scale_colour_manual(
   #name="Name",
   name = NULL,
   values = colors,
   labels = an,
   breaks = types
 ) +
 scale_linetype_manual(
   #name="Name",
   name = NULL,
   values = linetypes,
   labels = an,
   breaks = types
 ) +
 scale_size_manual(
   #name="Name",
   name = NULL,
   values = sizes,
   labels = an,
   breaks = types
 )
```

\subsection{2.6 Prueba Ji-Cuadrada de Pearson}

Se agrupan los datos de tal forma que todas las frecuencias de los datos observados sean mayores a 5:

```{r Prueba Chi-Square, echo=FALSE, warning=FALSE}
##Datos agrupados
nj<-NULL
agrupados1<-data.frame(cj_1=seq(0,max(sortedSeverities),5000), cj=seq(5000,max(sortedSeverities)+5000,5000))
                      
for(i in 1:length(agrupados1$cj_1)){
  nj[i]<-sum(montos<agrupados1$cj[i] & agrupados1$cj_1[i] <= montos)
}
agrupados1[3]<-nj
row.names(agrupados1)<-c(1:length(agrupados1$V3))

 agrupados<-agrupados1
k=1
while(agrupados$V3[k]>=5){
  aux <- k
k=k+1
}

  aux2<-0
  for(i in 1:(length(agrupados$V3)-aux)){
    aux2<-aux2+agrupados$V3[aux+i]
  }
agrupados$V3[aux+1]<-aux2

for(i in 1:(length(agrupados$cj)-aux-1)){
   agrupados$V3[aux+1+i]<-0
}

agrupados$cj[aux+1]<- agrupados$cj[length(agrupados$cj_1)]
 agrupados<-subset(agrupados, agrupados$V3>0) 
 agrupados<-rbind(agrupados,1)
 agrupados$cj_1[length(agrupados$V3)]<-agrupados$cj[length(agrupados$V3)-1]
 agrupados$cj[length(agrupados$cj)]<-"inf"
 agrupados$V3[length(agrupados$V3)]<-0
 kable(agrupados)

 ##Estimo el parámetro para una exponencial por MV
theta<-1/mean(montos)
E<-NULL
E[1]<-10000*(pexp(5000,theta))
for(i in 2:(length(agrupados$cj_1)-1)){
  E[i]<-10000*(pexp(as.numeric(agrupados$cj[i]),theta)-pexp(as.numeric(agrupados$cj_1[i]),theta))
}
E[length(agrupados$cj_1)]=10000*(1-pexp(as.numeric(agrupados$cj_1[length(agrupados$cj_1)]),theta))
agrupados[4]<-E

Q<-NULL
for(i in 1:(length(agrupados$cj_1))) {
  Q[i]<-((as.numeric(agrupados$V3[i])-as.numeric(agrupados$V4[i]))^2)/as.numeric(agrupados$V3[i])
}
Q[length(agrupados$cj_1)]=0
agrupados[5]<-Q
sumaQ<-sum(Q)
gl<-length(agrupados$cj_1)-3
test<-qchisq(.95,gl)

Rechazar <- sumaQ > test
```

Realizando la prueba Ji-Cuadrada, se tiene que la estadistica de prueba toma el siguite valor:
$$Q=`r sumaQ` < \chi_{(`r gl`),0.05}^2 = `r test`$$


Por lo tanto, la hipótesis de que la severidad sigue una distribución exponencial con media $10000$ no es rechazada.

```{r prueba, echo=FALSE, warning=FALSE, fig.width=4.5, fig.height=3, fig.align = "center"}
ggplot(data=data.frame(num=c("1","2","3"))) +
  stat_function(
    fun = dchisq,
    args = list(df = gl),
    xlim = c(test, 40),
    geom = "area",
    fill = moradito,
    color = "transparent",
    alpha = ".5"
    ) +
stat_function(
  fun = dchisq,
  args = list(df = gl),
  color = moradito
) +
geom_vline(
  aes(
    xintercept = sumaQ
  ),
  color = azulito
) +
geom_vline(
  aes(
    xintercept = test
  ),
  color="black"
) +
xlim(0,40) +
ylim(0,0.1) +
  labs(x = TeX('$x$'), y = TeX('$ f_{\\chi_{(14)}^2}(x) $')) + xAxis + yAxis + ggtitle("Prueba Ji-Cuadrada") + theme +
  annotate("text", x = 30, y = 0.01, label = "alpha==0.05", parse=TRUE) + 
  annotate("text", x = 10, y = 0.005, label = paste("Q==", sumaQ), parse=TRUE) +
  annotate("text", x = 30, y = 0.075, label = paste("{chi^{2}} ==", test), parse=TRUE)  
```

\subsection{2.7 El modelo ajustado sobreestima o subestima las probabilidades de eventos de monto alto}

Derivado del q-q plot no podemos concluir si el modelo sobreestima o subestima los datos ya que hay muy pocos valores por debajo y por arriba de la linea de 45 grados.

```{r echo=FALSE, warning=FALSE, message=FALSE}
##barplot(E)
#Monto
u2 <- runif(10000,0,1)
xi<-(-10000)*log(1-u2)
hist(xi,probability = TRUE,xlim = c(0,100000),breaks = 100,main = "Exponencial generada (10,000)")


#Q-Q Plot
Fn2 <- c(1:10000)
for (i in 1:10000){
  Fn2[i] <- (-10000)*log(1-(i/10001))
}

plot(sort(xi),Fn2, plot.it = TRUE) +
abline(lm(Fn2~sort(xi)), col="blue",lwd=1)

```



2.8 Suponiendo que la frecuencia anual se distribuye Poisson, estima su parámetro y construye un intervalo de confianza para la siniestralidad promedio.
```{r}

```


\section{3.1 Estimación con censura y truncamiento}

Sobre los 10000 siniestros simulados se considera que aplicarán un deducible de $5,000 y un límite de $30,000. El archivo de indemnizaciones queda de la siguiente manera (primeros 100 datos): 
```{r montos simulados, echo=FALSE, warning=FALSE}
##TRUNCAMIENTO
Indem<-montos
for ( i in 1:10000){
  
  if(Indem[i]<=5000){
    Indem[i]=0
  }
}
  for(i in 1:10000){
      if(Indem[i]>=30000){
        Indem[i]=25000
      }
  }
Indemnizacion<-as.data.frame(Indem)
Indem[1:100]
Indem1<-subset(Indem,Indem !=0)
```


La proporción de los datos originales que quedan es de 
```{r proporcion, echo=FALSE, warning=FALSE}
length(Indem1)
```
La estimación analítica de este número se verá más adelante.

\section{3.2 Estimación por máxima verosimilitud del parámetro de la distribución exponencial con la censura y el truncamiento}

```{r estimacion de lambda exponencial, echo=FALSE, warning=FALSE}

Indem2<-subset(Indem,Indem == 25000)
Indem3<-subset(Indem1,Indem1!= 25000)
Indem25<-length(Indem2)
Indemsin25<-length(Indem3)

Flog<-function(x){
 length(Indem2)*(-x*20000)+length(Indem3)*logb(x)- x*sum(Indem3)
}

##Resolviendo con Solver en Excel, tenemos que:
lambdaMV = .0000765113632847696
mediaEst = 1/lambdaMV
mediaDatos= mean(Indem1)

##Podemos observar que la media de los datos es mayor que la media estimada ya que la segunda considera la probabilidad de los siniestros menores al deducible

##La proporción de siniestros pagados calculada analíticamente es:
EstimAnalitica<-exp(-5000*lambdaMV)*10000

```

Después de resolver con Solver en Excel, se obtuvo que el parámetro de la distribución exponencial estimado por máxima verosimilitud es $.000076511$ y su media $13,069.95$. Comparada con la media que se obtuvo de los datos, que fue de $13,734.35$, se puede notar que el parámetro estimado considera los efectos de censura y truncamiento adecuadamente.

Analíticamente, la proporción estimada de los siniestros que se consideran indemnizaciones es de $6,821.151$.


\section{3.3 Intervalo de confianza para el percentil 95 de la severidad}
3.3 Construye un intervalo de confianza para el percentil 95 de la severidad. Compara este intervalo con el equivalente en la pregunta 2 y comenta.
```{r IC Severidad, echo=FALSE, warning=FALSE} 

```



